{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import sklearn as sk\n",
    "\n",
    "wineDF = pd.read_csv('winequality/winequality-red.csv',sep=';')\n",
    "seedsDF = pd.read_csv('seeds/seeds.csv',sep=',')\n",
    "\n",
    "class ProcessingData:\n",
    "    @staticmethod\n",
    "    def ShuffleData(df: pd.DataFrame):\n",
    "        for i in range(len(df)):\n",
    "            rand_i=rd.randint(0,len(df)-1)\n",
    "            df.loc[i],df.loc[rand_i] = df.loc[rand_i],df.loc[i]\n",
    "        return df\n",
    "    @staticmethod\n",
    "    def SplitData(df:pd.DataFrame,x:int,y:int):\n",
    "        if x+y>100:\n",
    "            print(\"Podano zbyt dużą ilość danych do podziału\")\n",
    "            return\n",
    "        train_set,test_set = pd.DataFrame(),pd.DataFrame()\n",
    "        for i in range(len(df)):\n",
    "            if rd.random()<x/100:\n",
    "                train_set = train_set.append(df.loc[i])\n",
    "            else:\n",
    "                test_set = test_set.append(df.loc[i])\n",
    "        return train_set,test_set\n",
    "    @staticmethod\n",
    "    def NormalizeData(df:pd.DataFrame):\n",
    "        for atributte in df.columns[:-1]:\n",
    "            mean = df[atributte].mean()\n",
    "            stddev = df[atributte].std()\n",
    "            df[atributte] = (df[atributte]-mean)/stddev\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Słaby score, poprawić.\n",
    "\n",
    "class NaiveBayes:\n",
    "    @staticmethod\n",
    "    def mean(df:pd.DataFrame,atributte:str):\n",
    "        return df[atributte].mean()\n",
    "    @staticmethod\n",
    "    def stddev(df:pd.DataFrame,atributte:str):\n",
    "        return df[atributte].std()\n",
    "    @staticmethod\n",
    "    def probability(df:pd.DataFrame,atributte:str,value:float,mean:float,stddev:float):\n",
    "        exponent = np.exp(-(value-mean)**2/(2*stddev**2))\n",
    "        return (1/(np.sqrt(2*np.pi)*stddev))*exponent\n",
    "    @staticmethod\n",
    "    def probability_class(sample:pd.Series,df:pd.DataFrame):\n",
    "        probability_class = {}\n",
    "        for Class in df.iloc[:,-1].unique():\n",
    "            probability_class[Class] = 1/len(df.iloc[:,-1].unique())\n",
    "            for atributte in sample.index:\n",
    "                if atributte == df.columns[-1]:\n",
    "                    continue\n",
    "                #calculate mean and stddev for atributte and class\n",
    "                mean = NaiveBayes.mean(df[df.iloc[:,-1]==Class],atributte)\n",
    "                stddev = NaiveBayes.stddev(df[df.iloc[:,-1]==Class],atributte)\n",
    "                probability_class[Class] *= NaiveBayes.probability(df[df.iloc[:,-1]==Class],atributte,sample[atributte],mean,stddev)\n",
    "        return max(probability_class,key=probability_class.get)\n",
    "    @staticmethod\n",
    "    def get_accuracy(df:pd.DataFrame,test_set:pd.DataFrame):\n",
    "        correct = 0\n",
    "        for i in range(len(test_set)):\n",
    "            if NaiveBayes.probability_class(df.iloc[i],df) == test_set.iloc[i][-1]:\n",
    "                correct += 1\n",
    "        print(\"Good predicted: \",correct)\n",
    "        print(\"Bad predicted: \",len(test_set)-correct)\n",
    "        return f\"{round((correct/len(test_set))*100,2)}%\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NaiveBayes:\n",
    "#     @staticmethod\n",
    "#     def mean(atr):\n",
    "#         return atr.mean()\n",
    "#     @staticmethod\n",
    "#     def stdev(atr):\n",
    "#         return atr.std()\n",
    "#     @staticmethod\n",
    "#     def prob(x,mean,stdev):\n",
    "#         if stdev == 0:\n",
    "#             return 0\n",
    "#         else:\n",
    "#             exponent = np.exp(-(x-mean)**2/(2*stdev**2))\n",
    "#             return (1/(np.sqrt(2*np.pi)*stdev))*exponent\n",
    "#     @staticmethod\n",
    "#     def classify(train_set: pd.DataFrame, sample):\n",
    "#         varieties = train_set[train_set.columns[-1]].unique()\n",
    "#         mean_std = {}\n",
    "#         probabilities = {}\n",
    "#         for variety in varieties:\n",
    "#             mean_std[variety] = {}\n",
    "#             for atr in train_set.columns:\n",
    "#                 if atr != train_set.columns[-1]:\n",
    "#                     mean_std[variety][atr] = [NaiveBayes.mean(train_set[train_set[train_set.columns[-1]] == variety][atr]),NaiveBayes.stdev(train_set[train_set[train_set.columns[-1]] == variety][atr])]\n",
    "#         for variety in varieties:\n",
    "#             probabilities[variety] = 1/len(varieties)\n",
    "#             for atr in sample.index:\n",
    "#                 if atr != train_set.columns[-1]:\n",
    "#                     probabilities[variety] *= NaiveBayes.prob(sample[atr],mean_std[variety][atr][0],mean_std[variety][atr][1])\n",
    "#         return max(probabilities,key=probabilities.get)\n",
    "#     @staticmethod\n",
    "#     def accuracy(test_set: pd.DataFrame, train_set: pd.DataFrame):\n",
    "#         correct = 0\n",
    "#         for i in range(len(test_set)):\n",
    "#             if test_set[train_set.columns[-1]].iloc[i] == NaiveBayes.classify(train_set,test_set.iloc[i]):\n",
    "#                 correct += 1\n",
    "#         print(\"Bad predicted: \"+str(len(test_set)-correct))\n",
    "#         return correct/len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good predicted:  21\n",
      "Bad predicted:  38\n",
      "35.59%\n"
     ]
    }
   ],
   "source": [
    "seedsDF = ProcessingData.NormalizeData(seedsDF)\n",
    "seedsDF = ProcessingData.ShuffleData(seedsDF)\n",
    "trainDF,testDF = ProcessingData.SplitData(seedsDF,70,30)\n",
    "print(NaiveBayes.get_accuracy(trainDF,testDF))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4108a91765b31e0749b701e6d0ff72b663ddb97904f65e23bc47690301cf2236"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
