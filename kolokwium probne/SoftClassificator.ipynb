{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import sklearn as sk\n",
    "\n",
    "wineDF = pd.read_csv('winequality/winequality-red.csv',sep=';')\n",
    "\n",
    "class ProcessingData:\n",
    "    @staticmethod\n",
    "    def ShuffleData(df: pd.DataFrame):\n",
    "        for i in range(len(df)):\n",
    "            rand_i=rd.randint(0,len(df)-1)\n",
    "            df.loc[i],df.loc[rand_i] = df.loc[rand_i],df.loc[i]\n",
    "        return df\n",
    "    @staticmethod\n",
    "    def SplitData(df:pd.DataFrame,x:int,y:int):\n",
    "        if x+y>100:\n",
    "            print(\"Podano zbyt dużą ilość danych do podziału\")\n",
    "            return\n",
    "        train_set,test_set = pd.DataFrame(),pd.DataFrame()\n",
    "        for i in range(len(df)):\n",
    "            if rd.random()<x/100:\n",
    "                train_set = train_set.append(df.loc[i])\n",
    "            else:\n",
    "                test_set = test_set.append(df.loc[i])\n",
    "        return train_set,test_set\n",
    "    @staticmethod\n",
    "    def NormalizeData(df:pd.DataFrame):\n",
    "        for atributte in df.columns[:-1]:\n",
    "            mean = df[atributte].mean()\n",
    "            stddev = df[atributte].std()\n",
    "            df[atributte] = (df[atributte]-mean)/stddev\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softClassificator:\n",
    "    @staticmethod\n",
    "    def fit(df: pd.DataFrame):\n",
    "        means = {}\n",
    "        mins = {}\n",
    "        maxes = {}\n",
    "        for Class in df.iloc[:,-1].unique():\n",
    "            means[Class] = {}\n",
    "            mins[Class] = {}\n",
    "            maxes[Class] = {}\n",
    "            for atributte in df.columns:\n",
    "                if atributte != df.columns[-1]:\n",
    "                    means[Class][atributte] = df[df.iloc[:,-1] == Class][atributte].mean()\n",
    "                    mins[Class][atributte] = df[df.iloc[:,-1] == Class][atributte].min()\n",
    "                    maxes[Class][atributte] = df[df.iloc[:,-1] == Class][atributte].max()\n",
    "                    for row in df.index:\n",
    "                        if df.loc[row,atributte] < means[Class][atributte]:\n",
    "                            df.loc[row,atributte] = 0\n",
    "                        else:\n",
    "                            df.loc[row,atributte] = 1\n",
    "        return df,means,mins,maxes\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_sample(sample:pd.Series, means:dict, mins:dict, maxes:dict) -> str:\n",
    "        for Class in means.keys():\n",
    "            for atributte in means[Class].keys():\n",
    "                if sample[atributte] < means[Class][atributte]:\n",
    "                    sample[atributte] = 0\n",
    "                else:\n",
    "                    sample[atributte] = 1\n",
    "        max_probability = 0\n",
    "        max_Class = \"\"\n",
    "        for Class in means.keys():\n",
    "            probability = 1\n",
    "            for atributte in means[Class].keys():\n",
    "                if sample[atributte] == 0:\n",
    "                    probability *= (1-means[Class][atributte])\n",
    "                else:\n",
    "                    probability *= means[Class][atributte]\n",
    "            if probability > max_probability:\n",
    "                max_probability = probability\n",
    "                max_Class = Class\n",
    "        return max_Class\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy(df: pd.DataFrame, means:dict, mins:dict, maxes:dict) -> float:\n",
    "        correct = 0\n",
    "        for row in df.index:\n",
    "            if df.loc[row,df.columns[-1]] == softClassificator.predict_sample(df.loc[row],means,mins,maxes):\n",
    "                correct += 1\n",
    "        return f\"{round(correct/len(df) * 100,2)}%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineDF = ProcessingData.NormalizeData(wineDF)\n",
    "wineDF = ProcessingData.ShuffleData(wineDF)\n",
    "train_set,test_set = ProcessingData.SplitData(wineDF,70,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.29%\n",
      "32.48%\n",
      "36.5%\n",
      "30.51%\n",
      "25.97%\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    wineDF = ProcessingData.ShuffleData(wineDF)\n",
    "    train_set,test_set = ProcessingData.SplitData(wineDF,70,30)\n",
    "    train_set,means,mins,maxes = softClassificator.fit(train_set)\n",
    "    print(softClassificator.accuracy(test_set,means,mins,maxes))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4108a91765b31e0749b701e6d0ff72b663ddb97904f65e23bc47690301cf2236"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
